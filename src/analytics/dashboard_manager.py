"""
Dashboard Manager pentru Analytics Avansat - OCR230
CreazÄƒ dashboard-uri interactive cu Plotly/Dash pentru analizÄƒ avansatÄƒ
"""

import os
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import dash
from dash import dcc, html, Input, Output, callback_context
import dash_bootstrap_components as dbc
from datetime import datetime, timedelta
import json
from typing import Dict, List, Optional
import sqlite3
from pathlib import Path

class DashboardManager:
    def __init__(self, output_folder: str, user_config: dict = None):
        self.output_folder = output_folder
        self.user_config = user_config or {}
        self.db_path = os.path.join(output_folder, "analytics.db")
        self.sessions_file = os.path.join(output_folder, "processing_sessions.json")
        self.live_stats_file = os.path.join(output_folder, "live_stats.json")  # Pentru statistici live
        self.current_session_id = None  # ID-ul sesiunii curente
        self._excel_last_modified = None  # Pentru a detecta modificÄƒri Excel
        self._processing_complete = False  # Flag pentru a opri refresh-urile inutile
        
        # Cache pentru datele finale - pentru a opri update-urile dupÄƒ procesare
        self._final_data_cache = None
        self._final_charts_cache = {}
        self._cache_created_at = None
        self._stop_updates_after_complete = False
        
        self.init_database()
        
    def init_database(self):
        """IniÈ›ializeazÄƒ baza de date pentru analytics"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Tabel pentru sesiunile de procesare
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS processing_sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_date TEXT,
                files_processed INTEGER,
                cnp_valid INTEGER,
                cnp_invalid INTEGER,
                duplicates_found INTEGER,
                processing_time REAL,
                avg_ocr_confidence REAL,
                errors_count INTEGER
            )
        ''')
        
        # Tabel pentru statistici detaliate pe judeÈ›e
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS county_stats (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id INTEGER,
                county_name TEXT,
                persons_count INTEGER,
                anaf_sector TEXT,
                avg_processing_time REAL,
                FOREIGN KEY (session_id) REFERENCES processing_sessions (id)
            )
        ''')
        
        # Tabel pentru performanÈ›a OCR
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS ocr_performance (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id INTEGER,
                file_name TEXT,
                processing_time REAL,
                ocr_confidence REAL,
                errors_detected INTEGER,
                cnp_extracted TEXT,
                FOREIGN KEY (session_id) REFERENCES processing_sessions (id)
            )
        ''')
        
        conn.commit()
        
        
        conn.close()
    
    def log_processing_session(self, session_data: Dict):
        """LogheazÄƒ o sesiune de procesare"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO processing_sessions 
            (session_date, files_processed, cnp_valid, cnp_invalid, duplicates_found, 
             processing_time, avg_ocr_confidence, errors_count)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            session_data.get('date', datetime.now().isoformat()),
            session_data.get('files_processed', 0),
            session_data.get('cnp_valid', 0),
            session_data.get('cnp_invalid', 0),
            session_data.get('duplicates_found', 0),
            session_data.get('processing_time', 0),
            session_data.get('avg_ocr_confidence', 0),
            session_data.get('errors_count', 0)
        ))
        
        session_id = cursor.lastrowid
        conn.commit()
        conn.close()
        return session_id
    
    def start_live_session(self):
        """Ãncepe o sesiune live de procesare"""
        # ReseteazÄƒ flag-ul de procesare completÄƒ pentru o nouÄƒ sesiune
        self._processing_complete = False
        self._excel_last_modified = None
        
        live_stats = {
            'session_start': datetime.now().isoformat(),
            'files_processed': 0,
            'cnp_valid': 0,
            'cnp_invalid': 0,
            'duplicates_found': 0,
            'current_file': '',
            'processing_speed': 0.0,
            'estimated_time_left': 0,
            'errors_count': 0
        }
        
        # SalveazÄƒ Ã®n fiÈ™ier pentru actualizare live
        with open(self.live_stats_file, 'w', encoding='utf-8') as f:
            json.dump(live_stats, f, indent=2)
        
        # CreeazÄƒ o sesiune Ã®n baza de date
        session_data = {
            'date': live_stats['session_start'],
            'files_processed': 0,
            'cnp_valid': 0,
            'cnp_invalid': 0,
            'duplicates_found': 0,
            'processing_time': 0,
            'avg_ocr_confidence': 0,
            'errors_count': 0
        }
        
        self.current_session_id = self.log_processing_session(session_data)
        print("ğŸ”„ NouÄƒ sesiune live Ã®nceputÄƒ - dashboard refresh reactivat")
        return self.current_session_id
    
    def update_live_stats(self, **kwargs):
        """ActualizeazÄƒ statisticile live"""
        try:
            # ÃncarcÄƒ statisticile curente
            if os.path.exists(self.live_stats_file):
                with open(self.live_stats_file, 'r', encoding='utf-8') as f:
                    live_stats = json.load(f)
            else:
                live_stats = {}
            
            # ActualizeazÄƒ cu noile valori
            for key, value in kwargs.items():
                live_stats[key] = value
            
            # CalculeazÄƒ viteza È™i timpul rÄƒmas
            if 'files_processed' in live_stats and 'session_start' in live_stats:
                start_time = datetime.fromisoformat(live_stats['session_start'])
                elapsed_time = (datetime.now() - start_time).total_seconds()
                
                if elapsed_time > 0 and live_stats['files_processed'] > 0:
                    live_stats['processing_speed'] = live_stats['files_processed'] / (elapsed_time / 60)  # fiÈ™iere/min
                    
                    if 'total_files' in live_stats and live_stats['processing_speed'] > 0:
                        remaining_files = live_stats['total_files'] - live_stats['files_processed']
                        live_stats['estimated_time_left'] = remaining_files / (live_stats['processing_speed'] / 60)
            
            # SalveazÄƒ statisticile actualizate
            with open(self.live_stats_file, 'w', encoding='utf-8') as f:
                json.dump(live_stats, f, indent=2)
                
            print(f"ğŸ”„ Live stats updated: {kwargs}")
            
        except Exception as e:
            print(f"âŒ Eroare la actualizarea statisticilor live: {e}")
    
    def mark_processing_complete(self):
        """MarcheazÄƒ procesarea ca fiind completÄƒ pentru a opri refresh-urile automate"""
        self._processing_complete = True
        print("âœ… Procesarea marcatÄƒ ca fiind completÄƒ - dashboard refresh automat va fi oprit")
    
    def reset_processing_state(self):
        """ReseteazÄƒ starea procesÄƒrii pentru o nouÄƒ sesiune"""
        self._processing_complete = False
        self._excel_last_modified = None
        print("ğŸ”„ Starea procesÄƒrii resetatÄƒ - dashboard refresh reactivat")
    
    def get_live_stats(self):
        """ObÈ›ine statisticile live curente"""
        try:
            if os.path.exists(self.live_stats_file):
                with open(self.live_stats_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"âš ï¸ Eroare la citirea statisticilor live: {e}")
        return {}
    
    def finish_live_session(self):
        """FinalizeazÄƒ sesiunea live È™i actualizeazÄƒ baza de date"""
        try:
            live_stats = self.get_live_stats()
            if live_stats and self.current_session_id:
                # CalculeazÄƒ timpul total de procesare
                start_time = datetime.fromisoformat(live_stats['session_start'])
                total_time = (datetime.now() - start_time).total_seconds()
                
                # ActualizeazÄƒ sesiunea Ã®n baza de date
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                
                cursor.execute('''
                    UPDATE processing_sessions 
                    SET files_processed = ?, cnp_valid = ?, cnp_invalid = ?, 
                        duplicates_found = ?, processing_time = ?, errors_count = ?
                    WHERE id = ?
                ''', (
                    live_stats.get('files_processed', 0),
                    live_stats.get('cnp_valid', 0),
                    live_stats.get('cnp_invalid', 0),
                    live_stats.get('duplicates_found', 0),
                    total_time,
                    live_stats.get('errors_count', 0),
                    self.current_session_id
                ))
                
                conn.commit()
                conn.close()
                
                # MARCHEAZÄ‚ procesarea ca fiind completÄƒ pentru a opri update-urile automate
                self._processing_complete = True  # ACTIVAT pentru a opri update-urile dashboard
                
                # PÄƒstreazÄƒ datele Ã®n fiÈ™ierul live pentru afiÈ™are continuÄƒ
                final_stats = live_stats.copy()
                final_stats['session_active'] = False
                final_stats['processing_speed'] = 0
                final_stats['estimated_time_left'] = 0
                
                with open(self.live_stats_file, 'w', encoding='utf-8') as f:
                    json.dump(final_stats, f, ensure_ascii=False, indent=2)
                
                print(f"âœ… Sesiunea live finalizatÄƒ: {live_stats['files_processed']} fiÈ™iere procesate")
                print("ï¿½ Datele rÄƒmÃ¢n disponibile Ã®n dashboard pentru vizualizare continuÄƒ")
                
        except Exception as e:
            print(f"âŒ Eroare la finalizarea sesiunii live: {e}")
        finally:
            self.current_session_id = None
    
    def _create_sample_data(self):
        """CreeazÄƒ date de test pentru dashboard"""
        import random
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        judete = ['BUCURESTI', 'CLUJ', 'TIMIS', 'BRASOV', 'CONSTANTA', 'IASI', 'DOLJ', 'GALATI', 'HUNEDOARA', 'PRAHOVA']
        
        # CreeazÄƒ 10 sesiuni de test din ultimele 30 de zile
        for i in range(10):
            date = datetime.now() - timedelta(days=random.randint(0, 30))
            files_proc = random.randint(5, 50)
            cnp_valid = random.randint(int(files_proc * 0.7), files_proc)
            cnp_invalid = files_proc - cnp_valid
            duplicates = random.randint(0, int(files_proc * 0.1))
            
            session_data = {
                'date': date.isoformat(),
                'files_processed': files_proc,
                'cnp_valid': cnp_valid,
                'cnp_invalid': cnp_invalid,
                'duplicates_found': duplicates,
                'processing_time': random.uniform(30, 300),
                'avg_ocr_confidence': random.uniform(75, 95),
                'errors_count': random.randint(0, 5)
            }
            
            cursor.execute('''
                INSERT INTO processing_sessions 
                (session_date, files_processed, cnp_valid, cnp_invalid, duplicates_found, 
                 processing_time, avg_ocr_confidence, errors_count)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                session_data['date'],
                session_data['files_processed'],
                session_data['cnp_valid'],
                session_data['cnp_invalid'],
                session_data['duplicates_found'],
                session_data['processing_time'],
                session_data['avg_ocr_confidence'],
                session_data['errors_count']
            ))
            
            session_id = cursor.lastrowid
            
            # AdaugÄƒ statistici pentru judeÈ›e
            for judet in random.sample(judete, random.randint(3, 7)):
                cursor.execute('''
                    INSERT INTO county_stats (session_id, county_name, persons_count, anaf_sector, avg_processing_time)
                    VALUES (?, ?, ?, ?, ?)
                ''', (
                    session_id,
                    judet,
                    random.randint(1, 15),
                    f"ANAF_{judet}",
                    random.uniform(5, 30)
                ))
        
        conn.commit()
        conn.close()
        print("âœ… Date de test create pentru dashboard!")
    
    def create_interactive_dashboard(self):
        """CreeazÄƒ dashboard-ul interactiv cu Dash"""
        app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])
        
        # InformaÈ›ii utilizator pentru personalizare
        user_name = self.user_config.get('name', 'Utilizator')
        user_ong = self.user_config.get('ong', 'OrganizaÈ›ie')
        user_email = self.user_config.get('email', '')
        user_admin_id = self.user_config.get('admin_id', '')
        
        app.layout = dbc.Container([
            # Header personalizat cu informaÈ›ii utilizator
            dbc.Row([
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H1("ğŸ“Š OCR230 - Dashboard Analytics", 
                                   className="text-center mb-2", 
                                   style={'color': '#2c3e50'}),
                            html.H4(f"ğŸ‘¤ {user_name}", 
                                   className="text-center mb-1", 
                                   style={'color': '#34495e'}),
                            html.H5(f"ğŸ¢ {user_ong}", 
                                   className="text-center mb-1", 
                                   style={'color': '#7f8c8d'}),
                            html.P(f"ğŸ“§ {user_email}" if user_email else "", 
                                  className="text-center mb-1", 
                                  style={'color': '#95a5a6', 'fontSize': '14px'}),
                            html.P(f"ğŸ†” ID: {user_admin_id}" if user_admin_id else "", 
                                  className="text-center mb-1", 
                                  style={'color': '#95a5a6', 'fontSize': '12px'}),
                            html.P(f"ğŸ“‚ Folder: {self.output_folder}", 
                                  className="text-center mb-0", 
                                  style={'color': '#bdc3c7', 'fontSize': '11px'})
                        ])
                    ], color="light")
                ])
            ], className="mb-4"),
            
            dbc.Row([
                dbc.Col([
                    html.Hr()
                ])
            ]),
            
            # Control Panel
            dbc.Row([
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H4("ğŸ›ï¸ Panou Control"),
                            dbc.Row([
                                dbc.Col([
                                    html.Label("Perioada:"),
                                    dcc.DatePickerRange(
                                        id='date-picker-range',
                                        start_date=datetime.now() - timedelta(days=30),
                                        end_date=datetime.now(),
                                        display_format='DD/MM/YYYY'
                                    )
                                ], width=6),
                                dbc.Col([
                                    html.Label("JudeÈ›:"),
                                    dcc.Dropdown(
                                        id='county-dropdown',
                                        options=[{'label': 'Toate JudeÈ›ele', 'value': 'all'}],
                                        value='all'
                                    )
                                ], width=6)
                            ]),
                            dbc.Row([
                                dbc.Col([
                                    dbc.Button("ğŸ”„ ActualizeazÄƒ", id="refresh-btn", color="primary", className="mt-2"),
                                    dbc.Button("ğŸ“¥ Export HTML", id="export-btn", color="success", className="mt-2 ms-2")
                                ])
                            ])
                        ])
                    ])
                ])
            ], className="mb-4"),
            
            # Statistici Generale + Live Stats
            dbc.Row([
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H4("ğŸ“ˆ Statistici Generale", className="card-title"),
                            dcc.Graph(id='general-stats-chart')
                        ])
                    ])
                ], width=6),
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H4("âš¡ Sesiune Live", className="card-title"),
                            dcc.Graph(id='live-stats-chart')
                        ])
                    ])
                ], width=6)
            ], className="mb-4"),
            
            # DistribuÈ›ie JudeÈ›e
            dbc.Row([
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H4("ğŸ—ºï¸ DistribuÈ›ie JudeÈ›e", className="card-title"),
                            dcc.Graph(id='county-distribution-chart')
                        ])
                    ])
                ])
            ], className="mb-4"),
            
            # Heatmap RomÃ¢nia È™i Performance OCR
            dbc.Row([
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H4("ğŸŒ¡ï¸ Heatmap RomÃ¢nia", className="card-title"),
                            dcc.Graph(id='romania-heatmap')
                        ])
                    ])
                ], width=8),
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H4("âš¡ Performance OCR", className="card-title"),
                            dcc.Graph(id='ocr-performance-chart')
                        ])
                    ])
                ], width=4)
            ], className="mb-4"),
            
            # Trending Temporal
            dbc.Row([
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H4("ğŸ“Š Trending Temporal", className="card-title"),
                            dcc.Graph(id='temporal-trends-chart')
                        ])
                    ])
                ])
            ], className="mb-4"),
            
            # Comparare Sesiuni
            dbc.Row([
                dbc.Col([
                    dbc.Card([
                        dbc.CardBody([
                            html.H4("ğŸ”„ Comparare Sesiuni", className="card-title"),
                            dcc.Graph(id='sessions-comparison-chart')
                        ])
                    ])
                ])
            ])
            
        ], fluid=True)
        
        # AdaugÄƒ un interval pentru refresh automat doar dacÄƒ procesarea nu este completÄƒ
        app.layout.children.append(
            dcc.Interval(
                id='interval-component',
                interval=3*1000,  # ActualizeazÄƒ la fiecare 3 secunde
                n_intervals=0,
                disabled=False  # Va fi dezactivat cÃ¢nd procesarea este completÄƒ
            )
        )
        
        # Callbacks pentru interactivitate
        self._setup_callbacks(app)
        
        return app
    
    def _setup_callbacks(self, app):
        """ConfigureazÄƒ callback-urile pentru dashboard"""
        
        @app.callback(
            [Output('general-stats-chart', 'figure'),
             Output('live-stats-chart', 'figure'),
             Output('county-distribution-chart', 'figure'),
             Output('romania-heatmap', 'figure'),
             Output('ocr-performance-chart', 'figure'),
             Output('temporal-trends-chart', 'figure'),
             Output('sessions-comparison-chart', 'figure'),
             Output('interval-component', 'disabled')],  # AdaugÄƒ control pentru interval
            [Input('refresh-btn', 'n_clicks'),
             Input('interval-component', 'n_intervals'),
             Input('date-picker-range', 'start_date'),
             Input('date-picker-range', 'end_date'),
             Input('county-dropdown', 'value')]
        )
        def update_dashboard(n_clicks, n_intervals, start_date, end_date, selected_county):
                    # VerificÄƒ dacÄƒ procesarea este completÄƒ pentru a opri intervalul
                    live_stats = self.get_live_stats()

                    # OPREÈ˜TE COMPLET UPDATE-URILE DUPÄ‚ PROCESARE
                    should_disable_interval = False

                    # VerificÄƒ IMEDIAT dacÄƒ procesarea s-a terminat - fÄƒrÄƒ sÄƒ mai aÈ™tepte intervale
                    if self._processing_complete:
                        should_disable_interval = True
                        print("âœ… Procesarea completÄƒ - OPRESC IMEDIAT toate update-urile dashboard!")

                        # ReturneazÄƒ ultimele chart-uri cached dacÄƒ sunt disponibile
                        if hasattr(self, '_final_charts_cache') and self._final_charts_cache:
                            return tuple(list(self._final_charts_cache.values()) + [should_disable_interval])
                        else:
                            # DacÄƒ nu avem cache, creeazÄƒ unul gol pentru a opri complet update-urile
                            empty_fig = go.Figure().add_annotation(text="Procesare completÄƒ - Dashboard oprit", x=0.5, y=0.5)
                            empty_charts = [empty_fig] * 7  # 7 chart-uri
                            return tuple(empty_charts + [should_disable_interval])

                    # VerificÄƒ È™i prin live_stats dacÄƒ sesiunea nu mai este activÄƒ
                    if live_stats and not live_stats.get('session_active', True):
                        should_disable_interval = True
                        print("âœ… Sesiune inactivÄƒ - OPRESC IMEDIAT toate update-urile dashboard!")
                        # Similar pentru sesiune inactivÄƒ
                        if hasattr(self, '_final_charts_cache') and self._final_charts_cache:
                            return tuple(list(self._final_charts_cache.values()) + [should_disable_interval])
                        else:
                            empty_fig = go.Figure().add_annotation(text="Sesiune inactivÄƒ - Dashboard oprit", x=0.5, y=0.5)
                            empty_charts = [empty_fig] * 7
                            return tuple(empty_charts + [should_disable_interval])

                    # ÃncarcÄƒ datele doar dacÄƒ nu trebuie sÄƒ oprim update-urile
                    if should_disable_interval and hasattr(self, '_final_charts_cache') and self._final_charts_cache:
                        # ReturneazÄƒ cache-ul final fÄƒrÄƒ sÄƒ mai facÄƒ query-uri
                        return tuple(list(self._final_charts_cache.values()) + [should_disable_interval])

                    data = self._load_analytics_data(start_date, end_date, selected_county)

                    # CreeazÄƒ graficele
                    general_stats = self._create_general_stats_chart(data)
                    live_stats_chart = self._create_live_stats_chart()
                    county_dist = self._create_county_distribution_chart(data)
                    romania_heatmap = self._create_romania_heatmap(data)
                    ocr_performance = self._create_ocr_performance_chart(data)
                    temporal_trends = self._create_temporal_trends_chart(data)
                    sessions_comparison = self._create_sessions_comparison_chart(data)

                    # SalveazÄƒ Ã®n cache pentru utilizare ulterioarÄƒ
                    self._final_charts_cache = {
                        'general_stats': general_stats,
                        'live_stats_chart': live_stats_chart,
                        'county_dist': county_dist,
                        'romania_heatmap': romania_heatmap,
                        'ocr_performance': ocr_performance,
                        'temporal_trends': temporal_trends,
                        'sessions_comparison': sessions_comparison
                    }

                    return (general_stats, live_stats_chart, county_dist, romania_heatmap, 
                           ocr_performance, temporal_trends, sessions_comparison, should_disable_interval)
    
    def _load_analytics_data(self, start_date, end_date, county_filter):
        """ÃncarcÄƒ datele pentru analytics din baza de date È™i Excel"""
        conn = sqlite3.connect(self.db_path)
        
        # Query principal pentru sesiuni
        query = '''
            SELECT * FROM processing_sessions 
            WHERE session_date BETWEEN ? AND ?
            ORDER BY session_date DESC
        '''
        
        sessions_df = pd.read_sql_query(query, conn, params=[start_date, end_date])
        
        # Query pentru statistici judeÈ›e
        county_query = '''
            SELECT cs.*, ps.session_date 
            FROM county_stats cs
            JOIN processing_sessions ps ON cs.session_id = ps.id
            WHERE ps.session_date BETWEEN ? AND ?
        '''
        
        if county_filter != 'all':
            county_query += ' AND cs.county_name = ?'
            params = [start_date, end_date, county_filter]
        else:
            params = [start_date, end_date]
            
        county_df = pd.read_sql_query(county_query, conn, params=params)
        conn.close()
        
        # ğŸ“Š ÃNCARCÄ‚ È˜I DATELE DIN EXCEL DACÄ‚ EXISTÄ‚
        excel_data = self._load_excel_data()
        if excel_data is not None:
            # IntegreazÄƒ datele din Excel cu cele din baza de date
            excel_counties = excel_data.groupby('ANAF_Apartin').size().reset_index(name='persons_count')
            excel_counties.columns = ['county_name', 'persons_count']
            excel_counties['session_date'] = datetime.now().isoformat()
            excel_counties['anaf_sector'] = excel_counties['county_name']
            excel_counties['avg_processing_time'] = 15.0  # valoare medie
            
            # CombinÄƒ datele
            if not county_df.empty:
                county_df = pd.concat([county_df, excel_counties], ignore_index=True)
            else:
                county_df = excel_counties
        
        return {
            'sessions': sessions_df,
            'counties': county_df
        }
    
    def _load_excel_data(self):
        """ÃncarcÄƒ datele din Excel dacÄƒ existÄƒ"""
        excel_path = os.path.join(self.output_folder, "Date_Persoane_OCR.xlsx")
        if os.path.exists(excel_path):
            try:
                # VerificÄƒ timpul de modificare pentru a evita Ã®ncÄƒrcÄƒri inutile
                current_modified = os.path.getmtime(excel_path)
                
                # DacÄƒ fiÈ™ierul nu s-a modificat È™i procesarea e completÄƒ, nu-l mai Ã®ncÄƒrca
                if (self._excel_last_modified == current_modified and 
                    self._processing_complete):
                    return None
                
                # DacÄƒ s-a modificat sau este prima Ã®ncÄƒrcare
                if self._excel_last_modified != current_modified:
                    df = pd.read_excel(excel_path, sheet_name='Date_Persoane')
                    self._excel_last_modified = current_modified
                    
                    # PrinteazÄƒ mesajul doar dacÄƒ procesarea nu este completÄƒ
                    if not self._processing_complete:
                        print(f"ğŸ“Š ÃncÄƒrcat Excel cu {len(df)} Ã®nregistrÄƒri")
                    
                    return df
                else:
                    # ReturneazÄƒ datele cached - ÃNTOTDEAUNA Ã®ncarcÄƒ datele pentru chart-uri
                    try:
                        df = pd.read_excel(excel_path, sheet_name='Date_Persoane')
                        return df
                    except Exception as e:
                        print(f"âš ï¸ Eroare la Ã®ncÄƒrcarea Excel pentru cache: {e}")
                        return None
                    
            except Exception as e:
                print(f"âš ï¸ Eroare la Ã®ncÄƒrcarea Excel: {e}")
                return None
        return None
    
    def _create_general_stats_chart(self, data):
        """CreeazÄƒ graficul cu statistici generale"""
        # ğŸ”¥ OBÈšINE STATISTICILE LIVE PENTRU A INCLUDE SESIUNEA CURENTÄ‚
        live_stats = self.get_live_stats()
        
        if data['sessions'].empty:
            # ÃncearcÄƒ sÄƒ Ã®ncarce date din Excel chiar dacÄƒ nu existÄƒ sesiuni
            excel_data = self._load_excel_data()
            if excel_data is not None:
                total_files = len(excel_data)
                total_valid_cnp = len(excel_data[excel_data['CNP'].notna()])
                total_invalid_cnp = total_files - total_valid_cnp
                
                # ğŸ“ˆ ADAUGÄ‚ DATELE LIVE LA TOTALURI DACÄ‚ EXISTÄ‚
                if live_stats:
                    total_files += live_stats.get('files_processed', 0)
                    total_valid_cnp += live_stats.get('cnp_valid', 0)
                    total_invalid_cnp += live_stats.get('cnp_invalid', 0)
                
                fig = go.Figure()
                
                fig.add_trace(go.Indicator(
                    mode = "number",
                    value = total_files,
                    title = {"text": "ğŸ“„ Total FiÈ™iere Procesate" + (" (Include Live)" if live_stats and live_stats.get('files_processed', 0) > 0 else "")},
                    domain = {'row': 0, 'column': 0}
                ))
                
                fig.add_trace(go.Indicator(
                    mode = "number+gauge",
                    value = (total_valid_cnp / (total_valid_cnp + total_invalid_cnp) * 100) if (total_valid_cnp + total_invalid_cnp) > 0 else 0,
                    title = {"text": "âœ… Rata CNP Complete (%)"},
                    gauge = {'axis': {'range': [None, 100]},
                            'bar': {'color': "green"},
                            'steps': [{'range': [0, 50], 'color': "lightgray"},
                                     {'range': [50, 80], 'color': "yellow"},
                                     {'range': [80, 100], 'color': "lightgreen"}]},
                    domain = {'row': 0, 'column': 1}
                ))
                
                fig.update_layout(
                    grid = {'rows': 1, 'columns': 2, 'pattern': "independent"},
                    height=300,
                    title="Statistici Generale" + (" + Live Session" if live_stats and live_stats.get('files_processed', 0) > 0 else "")
                )
                
                return fig
            else:
                # DacÄƒ nu existÄƒ nici Excel nici sesiuni, dar existÄƒ date live
                if live_stats and live_stats.get('files_processed', 0) > 0:
                    fig = go.Figure()
                    
                    fig.add_trace(go.Indicator(
                        mode = "number",
                        value = live_stats.get('files_processed', 0),
                        title = {"text": "ğŸ“„ Total FiÈ™iere Procesate (Live)"},
                        domain = {'row': 0, 'column': 0}
                    ))
                    
                    total_cnp = live_stats.get('cnp_valid', 0) + live_stats.get('cnp_invalid', 0)
                    cnp_rate = (live_stats.get('cnp_valid', 0) / total_cnp * 100) if total_cnp > 0 else 0
                    
                    fig.add_trace(go.Indicator(
                        mode = "number+gauge",
                        value = cnp_rate,
                        title = {"text": "âœ… Rata CNP Complete (%)"},
                        gauge = {'axis': {'range': [None, 100]},
                                'bar': {'color': "green"},
                                'steps': [{'range': [0, 50], 'color': "lightgray"},
                                         {'range': [50, 80], 'color': "yellow"},
                                         {'range': [80, 100], 'color': "lightgreen"}]},
                        domain = {'row': 0, 'column': 1}
                    ))
                    
                    fig.update_layout(
                        grid = {'rows': 1, 'columns': 2, 'pattern': "independent"},
                        height=300,
                        title="Statistici Live"
                    )
                    
                    return fig
                else:
                    return go.Figure().add_annotation(text="Nu existÄƒ date disponibile. RuleazÄƒ o procesare pentru a vedea statistici.", x=0.5, y=0.5)
        
        df = data['sessions']
        
        # CalculeazÄƒ totalurile din sesiunile anterioare
        total_files = df['files_processed'].sum()
        total_valid_cnp = df['cnp_valid'].sum()
        total_invalid_cnp = df['cnp_invalid'].sum()
        total_duplicates = df['duplicates_found'].sum()
        
        # ğŸ”¥ ADAUGÄ‚ DATELE LIVE LA TOTALURI DACÄ‚ EXISTÄ‚ O SESIUNE ACTIVÄ‚
        if live_stats and live_stats.get('files_processed', 0) > 0:
            total_files += live_stats.get('files_processed', 0)
            total_valid_cnp += live_stats.get('cnp_valid', 0)
            total_invalid_cnp += live_stats.get('cnp_invalid', 0)
            total_duplicates += live_stats.get('duplicates_found', 0)
        
        fig = go.Figure()
        
        # AdaugÄƒ indicatori
        fig.add_trace(go.Indicator(
            mode = "number+delta",
            value = total_files,
            title = {"text": "ğŸ“„ Total FiÈ™iere Procesate" + (" (Include Live)" if live_stats and live_stats.get('files_processed', 0) > 0 else "")},
            domain = {'row': 0, 'column': 0}
        ))
        
        fig.add_trace(go.Indicator(
            mode = "number+gauge",
            value = (total_valid_cnp / (total_valid_cnp + total_invalid_cnp) * 100) if (total_valid_cnp + total_invalid_cnp) > 0 else 0,
            title = {"text": "âœ… Rata CNP Valide (%)"},
            gauge = {'axis': {'range': [None, 100]},
                    'bar': {'color': "green"},
                    'steps': [{'range': [0, 50], 'color': "lightgray"},
                             {'range': [50, 80], 'color': "yellow"},
                             {'range': [80, 100], 'color': "lightgreen"}]},
            domain = {'row': 0, 'column': 1}
        ))
        
        fig.update_layout(
            grid = {'rows': 1, 'columns': 2, 'pattern': "independent"},
            height=300,
            title="Statistici din Sesiuni de Procesare" + (" + Live Session" if live_stats and live_stats.get('files_processed', 0) > 0 else "")
        )
        
        return fig
    
    def _create_live_stats_chart(self):
        """CreeazÄƒ graficul cu statistici live din sesiunea curentÄƒ"""
        live_stats = self.get_live_stats()
        
        # DacÄƒ nu avem date live, Ã®ncarcÄƒ ultimele date din baza de date
        if not live_stats:
            # ÃncearcÄƒ sÄƒ Ã®ncÄƒrce datele din ultima sesiune
            conn = sqlite3.connect(self.db_path)
            try:
                query = "SELECT * FROM processing_sessions ORDER BY session_date DESC LIMIT 1"
                result = pd.read_sql_query(query, conn)
                if not result.empty:
                    latest_session = result.iloc[0]
                    live_stats = {
                        'files_processed': latest_session['files_processed'],
                        'total_files': latest_session['files_processed'],  # Folosim acelaÈ™i numÄƒr
                        'cnp_valid': latest_session['cnp_valid'],
                        'cnp_invalid': latest_session['cnp_invalid'],
                        'processing_speed': 0,  # Procesarea s-a terminat
                        'estimated_time_left': 0,
                        'session_active': False
                    }
            except Exception as e:
                print(f"âš ï¸ Nu s-au putut Ã®ncÄƒrca datele din baza de date: {e}")
            finally:
                conn.close()
        
        # DacÄƒ tot nu avem date, afiÈ™eazÄƒ mesaj
        if not live_stats:
            return go.Figure().add_annotation(
                text="Nu existÄƒ date de procesare disponibile",
                x=0.5, y=0.5,
                showarrow=False,
                font=dict(size=16, color="gray")
            )
        
        # DeterminÄƒ statusul procesÄƒrii
        is_active = live_stats.get('session_active', False) or live_stats.get('processing_speed', 0) > 0
        status_text = "ğŸŸ¢ Procesare ACTIVÄ‚" if is_active else "ğŸ”´ Procesare COMPLETÄ‚"
        
        # CreeazÄƒ indicatori pentru sesiunea live
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=("FiÈ™iere Procesate", f"CNP Valide - {status_text}"),
            specs=[[{"type": "indicator"}, {"type": "indicator"}],
                   [{"type": "indicator"}, {"type": "indicator"}]],
            vertical_spacing=0.25
        )
        
        # FiÈ™iere procesate
        fig.add_trace(go.Indicator(
            mode="number+gauge",
            value=live_stats.get('files_processed', 0),
            title={"text": "FiÈ™iere"},
            gauge={'axis': {'range': [None, live_stats.get('total_files', 100)]},
                   'bar': {'color': "darkblue"},
                   'steps': [{'range': [0, live_stats.get('total_files', 100) * 0.5], 'color': "lightgray"},
                            {'range': [live_stats.get('total_files', 100) * 0.5, live_stats.get('total_files', 100)], 'color': "gray"}],
                   'threshold': {'line': {'color': "red", 'width': 4},
                                'thickness': 0.75, 'value': live_stats.get('total_files', 100)}}
        ), row=1, col=1)
        
        # CNP Valide
        total_cnp = live_stats.get('cnp_valid', 0) + live_stats.get('cnp_invalid', 0)
        cnp_rate = (live_stats.get('cnp_valid', 0) / total_cnp * 100) if total_cnp > 0 else 0
        
        fig.add_trace(go.Indicator(
            mode="number+gauge",
            value=cnp_rate,
            title={"text": "CNP (%)"},
            gauge={'axis': {'range': [None, 100]},
                   'bar': {'color': "green"},
                   'steps': [{'range': [0, 70], 'color': "lightgray"},
                            {'range': [70, 90], 'color': "yellow"},
                            {'range': [90, 100], 'color': "lightgreen"}]}
        ), row=1, col=2)
        
        # VitezÄƒ procesare
        fig.add_trace(go.Indicator(
            mode="number",
            value=live_stats.get('processing_speed', 0),
            title={"text": "VitezÄƒ Procesare (fiÈ™iere/min)"},
            number={'suffix': " f/min"}
        ), row=2, col=1)
        
        # Timp rÄƒmas
        eta = live_stats.get('estimated_time_left', 0)
        eta_unit = "min" if eta > 60 else "sec"
        eta_value = eta/60 if eta > 60 else eta
        
        fig.add_trace(go.Indicator(
            mode="number",
            value=eta_value,
            title={"text": f"ETA ({eta_unit})"},
            number={'suffix': f" {eta_unit}"}
        ), row=2, col=2)
        
        fig.update_layout(
            height=350,  # MÄƒresc Ã®nÄƒlÈ›imea È™i mai mult pentru spaÈ›iu optim
            title_text="ğŸ”¥ Sesiune Live de Procesare",
            title_x=0.5
        )
        
        return fig
    
    def _create_county_distribution_chart(self, data):
        """CreeazÄƒ graficul de distribuÈ›ie pe judeÈ›e"""
        if data['counties'].empty:
            # ÃncearcÄƒ sÄƒ Ã®ncarce din Excel
            excel_data = self._load_excel_data()
            if excel_data is not None and 'ANAF_Apartin' in excel_data.columns:
                county_counts = excel_data['ANAF_Apartin'].value_counts().head(10)
                df = pd.DataFrame({
                    'county_name': county_counts.index,
                    'persons_count': county_counts.values
                })
                
                fig = px.bar(df, x='county_name', y='persons_count',
                            title="Top 10 JudeÈ›e din Excel",
                            labels={'county_name': 'JudeÈ›', 'persons_count': 'NumÄƒr Persoane'})
                fig.update_layout(height=300)
                return fig
            else:
                return go.Figure().add_annotation(text="Nu existÄƒ date despre judeÈ›e")
        
        df = data['counties'].groupby('county_name')['persons_count'].sum().reset_index()
        df = df.sort_values('persons_count', ascending=False).head(10)
        
        fig = px.bar(df, x='county_name', y='persons_count',
                    title="Top 10 JudeÈ›e dupÄƒ numÄƒrul de persoane",
                    labels={'county_name': 'JudeÈ›', 'persons_count': 'NumÄƒr Persoane'})
        
        fig.update_layout(height=300)
        return fig
    
    def _create_romania_heatmap(self, data):
        """CreeazÄƒ heatmap-ul pentru RomÃ¢nia"""
        if data['counties'].empty:
            return go.Figure().add_annotation(text="Nu existÄƒ date disponibile")
        
        # Simulare coordonate pentru judeÈ›e (Ã®n practicÄƒ ai nevoie de un fiÈ™ier GeoJSON)
        county_stats = data['counties'].groupby('county_name').agg({
            'persons_count': 'sum',
            'avg_processing_time': 'mean'
        }).reset_index()
        
        # Pentru demonstraÈ›ie, creez un scatter plot
        # Ãn realitate ai avea nevoie de coordonatele geografice ale judeÈ›elor
        fig = px.scatter(county_stats, 
                        x='county_name', 
                        y='persons_count',
                        size='persons_count',
                        color='avg_processing_time',
                        title="Intensitatea procesÄƒrii pe judeÈ›e",
                        labels={'county_name': 'JudeÈ›', 'persons_count': 'Nr. Persoane'})
        
        fig.update_layout(height=400)
        return fig
    
    def _create_ocr_performance_chart(self, data):
        """CreeazÄƒ graficul de performanÈ›Äƒ OCR"""
        if data['sessions'].empty:
            return go.Figure().add_annotation(text="Nu existÄƒ date disponibile")
        
        df = data['sessions']
        
        fig = go.Figure()
        
        # Timpul mediu de procesare
        fig.add_trace(go.Scatter(
            x=df['session_date'],
            y=df['processing_time'],
            mode='lines+markers',
            name='Timp procesare (s)',
            line=dict(color='blue')
        ))
        
        # Ãncrederea OCR
        fig.add_trace(go.Scatter(
            x=df['session_date'],
            y=df['avg_ocr_confidence'],
            mode='lines+markers',
            name='Ãncredere OCR (%)',
            yaxis='y2',
            line=dict(color='green')
        ))
        
        fig.update_layout(
            title="PerformanÈ›a OCR Ã®n timp",
            xaxis_title="Data",
            yaxis=dict(title="Timp procesare (s)", side="left"),
            yaxis2=dict(title="Ãncredere OCR (%)", side="right", overlaying="y"),
            height=300
        )
        
        return fig
    
    def _create_temporal_trends_chart(self, data):
        """CreeazÄƒ graficul de trending temporal"""
        if data['sessions'].empty:
            return go.Figure().add_annotation(text="Nu existÄƒ date disponibile")
        
        df = data['sessions'].copy()
        df['session_date'] = pd.to_datetime(df['session_date'])
        df = df.sort_values('session_date')
        
        fig = make_subplots(rows=2, cols=1, 
                           subplot_titles=('FiÈ™iere procesate Ã®n timp', 'Calitatea procesÄƒrii'),
                           specs=[[{"secondary_y": False}], [{"secondary_y": True}]])
        
        # FiÈ™iere procesate
        fig.add_trace(go.Scatter(x=df['session_date'], y=df['files_processed'],
                                mode='lines+markers', name='FiÈ™iere procesate'),
                     row=1, col=1)
        
        # CNP valide vs invalide
        fig.add_trace(go.Scatter(x=df['session_date'], y=df['cnp_valid'],
                                mode='lines+markers', name='CNP Valide'),
                     row=2, col=1)
        
        fig.add_trace(go.Scatter(x=df['session_date'], y=df['cnp_invalid'],
                                mode='lines+markers', name='CNP Invalide'),
                     row=2, col=1)
        
        fig.update_layout(height=500, title_text="Trending Temporal - Activitate Procesare")
        return fig
    
    def _create_sessions_comparison_chart(self, data):
        """CreeazÄƒ graficul de comparare Ã®ntre sesiuni"""
        if data['sessions'].empty:
            return go.Figure().add_annotation(text="Nu existÄƒ date disponibile")
        
        df = data['sessions'].tail(5)  # Ultimele 5 sesiuni
        
        categories = ['FiÈ™iere procesate', 'CNP Valide', 'CNP Invalide', 'Duplicate gÄƒsite']
        
        fig = go.Figure()
        
        for idx, row in df.iterrows():
            fig.add_trace(go.Scatterpolar(
                r=[row['files_processed'], row['cnp_valid'], row['cnp_invalid'], row['duplicates_found']],
                theta=categories,
                fill='toself',
                name=f"Sesiunea {row['session_date'][:10]}"
            ))
        
        fig.update_layout(
            polar=dict(
                radialaxis=dict(visible=True)
            ),
            title="Comparare Sesiuni de Procesare",
            height=400
        )
        
        return fig
    
    def export_dashboard_html(self, filename: Optional[str] = None):
        """ExportÄƒ dashboard-ul ca HTML pentru prezentÄƒri"""
        if not filename:
            filename = f"OCR230_Dashboard_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
        
        # CreeazÄƒ dashboard-ul
        app = self.create_interactive_dashboard()
        
        # GenereazÄƒ HTML static (aici ai nevoie de o implementare mai complexÄƒ)
        # Pentru moment, salvez configuraÈ›ia
        export_path = os.path.join(self.output_folder, filename)
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>OCR230 Dashboard Export</title>
            <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
        </head>
        <body>
            <h1>OCR230 Analytics Dashboard - Export</h1>
            <p>Generat pe: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}</p>
            <p>Pentru dashboard interactiv complet, rulaÈ›i aplicaÈ›ia OCR230.</p>
        </body>
        </html>
        """
        
        with open(export_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        return export_path

# FuncÈ›ie utilitarÄƒ pentru lansarea dashboard-ului
def launch_dashboard(output_folder: str, port: int = 8050, analytics_manager_instance=None, user_config: dict = None):
    """
    LanseazÄƒ dashboard-ul analytics cu gestionare Ã®mbunÄƒtÄƒÈ›itÄƒ a porturilor
    
    Args:
        output_folder: Folderul cu datele de output
        port: Portul pe care sÄƒ ruleze (default 8050)
        analytics_manager_instance: InstanÈ›Äƒ existentÄƒ de DashboardManager (opÈ›ional)
        user_config: ConfiguraÈ›ia utilizatorului pentru personalizare (opÈ›ional)
    """
    import socket
    import threading
    import webbrowser
    import time
    
    def find_free_port(start_port: int = 8050) -> int:
        """GÄƒseÈ™te un port liber Ã®ncepÃ¢nd cu start_port"""
        for port_try in range(start_port, start_port + 10):
            try:
                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                    s.bind(('127.0.0.1', port_try))
                    return port_try
            except OSError:
                continue
        raise RuntimeError("Nu s-a gÄƒsit niciun port liber Ã®ntre 8050-8059")
    
    def start_server():
        """PorneÈ™te serverul Dash Ã®n thread separat"""
        try:
            # FoloseÈ™te instanÈ›a existentÄƒ sau creeazÄƒ una nouÄƒ
            if analytics_manager_instance is not None:
                dashboard = analytics_manager_instance
                # ActualizeazÄƒ configuraÈ›ia utilizatorului dacÄƒ este furnizatÄƒ
                if user_config:
                    dashboard.user_config = user_config
                print("ğŸ”— Folosesc instanÈ›a existentÄƒ de DashboardManager")
            else:
                dashboard = DashboardManager(output_folder, user_config)
                print("ğŸ†• Creez o nouÄƒ instanÈ›Äƒ de DashboardManager")
                
            app = dashboard.create_interactive_dashboard()
            
            # GÄƒseÈ™te un port liber
            free_port = find_free_port(port)
            url = f"http://127.0.0.1:{free_port}"
            
            print(f"ğŸš€ LansÃ¢nd dashboard analytics pe {url}")
            
            # Deschide browser-ul automat dupÄƒ o scurtÄƒ Ã®ntÃ¢rziere
            def open_browser():
                time.sleep(2)
                try:
                    webbrowser.open(url)
                    print(f"âœ… Browser deschis automat pentru {url}")
                except Exception as e:
                    print(f"âš ï¸ Nu s-a putut deschide browser-ul automat: {e}")
                    print(f"ğŸ”— AcceseazÄƒ manual: {url}")
            
            threading.Thread(target=open_browser, daemon=True).start()
            
            # PorneÈ™te serverul
            app.run(debug=False, port=free_port, host='127.0.0.1')
            
        except Exception as e:
            print(f"âŒ Eroare la lansarea dashboard-ului: {e}")
            import traceback
            traceback.print_exc()
    
    # PorneÈ™te serverul Ã®n thread separat pentru a nu bloca UI-ul
    server_thread = threading.Thread(target=start_server, daemon=True)
    server_thread.start()
    
    return server_thread

if __name__ == "__main__":
    # Test
    test_folder = "test_output"
    os.makedirs(test_folder, exist_ok=True)
    
    # Test cu configuraÈ›ie utilizator
    test_user_config = {
        'name': 'Ion Popescu',
        'ong': 'ONG Test RomÃ¢nia',
        'email': 'ion.popescu@test.ro',
        'admin_id': 'TEST001'
    }
    
    dashboard = DashboardManager(test_folder, test_user_config)
    
    # Simulare date pentru test
    test_session = {
        'date': datetime.now().isoformat(),
        'files_processed': 25,
        'cnp_valid': 23,
        'cnp_invalid': 2,
        'duplicates_found': 1,
        'processing_time': 125.5,
        'avg_ocr_confidence': 87.3,
        'errors_count': 2
    }
    
    dashboard.log_processing_session(test_session)
    print("âœ… Test dashboard creat cu succes!")
    
    # Test lansare dashboard
    launch_dashboard(test_folder, user_config=test_user_config)
